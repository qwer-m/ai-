# AI技术辅助测试平台系统需求文档

## 1. 引言

### 1.1 文档目的
本文档旨在明确“AI技术辅助测试平台”的功能需求与非功能需求，为系统的开发、测试及维护提供统一的基准。

### 1.2 系统概述
本系统是一个基于人工智能（LLM + RAG）技术的综合测试辅助平台，旨在通过AI能力自动化生成测试用例、自动化测试脚本（UI/API），并提供项目化管理、知识库支持及质量评估功能，以提升软件测试的效率与覆盖率。

---

## 2. 功能需求

### 2.1 项目管理模块 (Project Management)
**目标**：提供多层级的组织结构，隔离不同业务线的测试资产。

1.  **项目层级管理**：
    *   支持创建最多 3 级的父子项目结构（例如：产品线 -> 子系统 -> 模块）。
    *   支持查看项目树状结构图。
2.  **项目生命周期管理**：
    *   **创建**：支持定义项目名称、描述及父级项目。
    *   **查询**：支持展示项目列表及详情。
    *   **更新**：支持修改项目基本信息。
    *   **删除**：支持级联删除项目，自动清理关联的知识库、测试用例、日志等数据。
3.  **数据隔离**：
    *   确保所有业务数据（用例、文档、日志）严格按 Project ID 进行逻辑隔离。

### 2.2 测试用例生成模块 (Test Generation)
**目标**：利用大模型根据需求自动生成结构化测试用例。

1.  **多模态需求输入**：
    *   **文本输入**：支持直接输入需求描述文本。
    *   **文件上传**：支持上传 PDF, Word (.docx), TXT, Markdown (.md) 及图片文件。
    *   **OCR 识别**：支持自动提取上传图片中的文字内容。
2.  **文档类型支持**：
    *   **需求文档**：处理标准文本需求。
    *   **原型图**：基于 UI 原型图分析生成交互测试用例。
    *   **残缺文档**：支持“文本 + 原型图”组合输入，AI 自动补充缺失逻辑。
    *   **产品需求**：处理高层级业务需求。
3.  **智能生成策略**：
    *   **RAG 检索增强**：自动检索知识库中相关的历史文档作为生成上下文。
    *   **上下文压缩**：针对超长输入，自动生成摘要以适配模型 Token 限制。
    *   **结构化输出与修复**：生成包含 ID、标题、前置条件、步骤、预期结果的 JSON 数据，并内置自动修复机制处理格式错误。
    *   **批量生成**：支持单次批量生成多个用例，并自动进行编号（如 TC-001）。
4.  **结果管理**：
    *   **在线预览**：以表格形式展示生成的测试用例。
    *   **导出**：支持导出为 Excel (.xlsx) 或 CSV 格式。
    *   **历史记录**：自动保存生成历史供后续回溯。

### 2.3 知识库管理模块 (Knowledge Base)
**目标**：构建项目专属知识库，为 AI 提供准确的上下文参考。

1.  **文档管理**：
    *   **上传**：支持上传需求、设计文档、测试用例等文件，并指定文档类型。
    *   **列表管理**：分页展示文档列表，支持按文件名、类型、时间筛选。
    *   **预览与摘要**：支持鼠标悬浮预览文档内容摘要及关联信息。
    *   **删除**：支持删除文档及其向量索引。
2.  **关联分析**：
    *   **自动关联**：识别需求文档与测试用例之间的关联关系。
    *   **关联展示**：在列表中直观展示文档关联的测试用例（包括文件名及摘要）。
3.  **数据清理**：
    *   提供工具一键清理跨项目的无效关联数据。

### 2.4 UI 自动化模块 (UI Automation)
**目标**：通过自然语言描述自动生成并执行 UI 自动化脚本。

1.  **跨平台支持**：
    *   **Web 端**：基于 Selenium 生成浏览器自动化脚本。
    *   **移动端**：基于 Appium 生成移动应用自动化脚本。
    *   **桌面端**：基于 PyAutoGUI 生成桌面操作脚本。
2.  **智能脚本生成**：
    *   基于“目标地址/包名”和“任务步骤描述”（如“登录账号 admin”）自动生成 Python 代码。
    *   支持利用 AI 视觉能力辅助定位 UI 元素坐标。
3.  **在线执行与反馈**：
    *   支持在服务端沙箱环境中直接运行生成的脚本。
    *   实时流式回显执行日志与结果。

### 2.5 接口测试模块 (API Testing)
**目标**：自动生成接口测试脚本并验证接口功能。

1.  **脚本生成**：
    *   根据接口定义或自然语言需求，自动生成 Python (`requests`) 测试脚本。
2.  **执行与验证**：
    *   在线执行脚本，捕获并展示 HTTP 响应状态码、响应体及错误信息。

### 2.6 质量评估模块 (Evaluation)
**目标**：监控 AI 生成质量，形成反馈闭环。

1.  **生成质量指标**：
    *   自动统计正向用例、负向用例、边界值用例的分布比例。
    *   统计平均步骤数、待确认项（Pending）数量。
    *   可视化图表展示生成趋势。
2.  **对比评估**：
    *   **Diff 分析**：对比“AI 初始生成版本”与“人工修订版本”，计算修改率。
    *   **自动评分**：AI 对比两个版本，生成质量评分与改进建议。
3.  **检索评估 (Recall)**：
    *   评估 RAG 检索的准确率与召回率（Retrieved vs Relevant）。
4.  **代码质量评估**：
    *   对生成的自动化脚本进行静态代码分析与评分。

### 2.7 系统基础设施
1.  **日志系统**：
    *   **用户操作日志**：记录关键业务操作。
    *   **系统运行日志**：记录后台异常、API 调用错误及性能告警。
    *   支持按日志级别（Error/Info）筛选查看。
2.  **健康监控**：
    *   实时检测 MySQL 数据库连接状态。
    *   实时检测 Redis 缓存服务连接状态。
3.  **配置管理**：
    *   支持在线热更新 LLM 模型配置（API Key、模型名称、Provider）。

---

## 3. 非功能需求

1.  **响应性**：前端界面需支持自适应布局，适配不同分辨率屏幕（Flex 布局优化）。
2.  **持久化**：
    *   关键业务数据存储于 MySQL。
    *   向量数据及缓存存储于 Redis/VectorDB。
    *   前端表单状态（如文件选择）需支持持久化，防止刷新丢失。
3.  **易用性**：
    *   提供清晰的加载状态提示（Loading Spinners）。
    *   关键操作（如删除）需提供二次确认。
    *   支持鼠标悬浮查看详细信息，减少页面跳转。
