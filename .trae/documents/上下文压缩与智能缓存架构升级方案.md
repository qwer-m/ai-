# 上下文压缩与智能缓存架构升级方案

本计划旨在通过引入多层缓存、持久化存储及多模型调度机制，解决大模型应用中上下文过长、响应慢及成本高的问题，并增强系统的容错能力。

## 1. 核心架构升级 (后端)

### 1.1 四层缓存架构设计
我们将实现一个分层的缓存服务 `CacheService`，集成 Redis（或本地高性能文件缓存）与 MySQL。
- **L1 请求级缓存 (Memory/Redis)**: 
  - **内容**: 完整的 API 请求与响应对。
  - **策略**: TTL (Time To Live) 短期缓存，用于处理短时间内的重复点击。
- **L2 需求特征缓存 (Smart Index)**:
  - **内容**: 需求的特征哈希（SHA256）与生成的测试用例/脚本。
  - **策略**: 持久化存储，只要需求文字不大改，直接复用已有生成结果。
- **L3 项目知识缓存 (MySQL)**:
  - **内容**: 针对项目知识库文档的**预压缩摘要**。
  - **策略**: 文档上传时自动生成摘要存入数据库，RAG 检索时优先使用摘要。
- **L4 模型响应缓存 (MySQL)**:
  - **内容**: `Prompt` -> `Model Response` 的原始映射。
  - **策略**: 避免相同的底层 Prompt 重复消耗 Token。

### 1.2 多模型调度器 (Dispatcher)
重构 `AIClient`，从单一模型调用转变为调度器模式。
- **抽象接口**: 定义 `BaseModelProvider`。
- **实现类**: `DashScopeProvider` (Qwen), `OpenAIProvider` (GPT-4), `LocalProvider` (预留)。
- **调度逻辑**: 
  - 优先检查 L1-L4 缓存。
  - 未命中时，根据任务类型（简单摘要 vs 复杂生成）选择模型。
  - **故障转移**: 主模型调用失败（如额度耗尽）时，自动标记并触发异常处理流程。

## 2. 功能实现：上下文压缩

### 2.1 智能压缩流程
- **写入时处理**: 上传文档时，异步调用 `Qwen-Turbo` 生成文档摘要，并存入 `KnowledgeDocument` 表的新字段 `summary`。
- **读取时优化**: 在 `test_generator` 和 `knowledge_base` 模块中，构建 Prompt 时优先使用 `summary`。若 `summary` 信息不足，再回退到全文。

## 3. 用户体验：动态配置与额度告警 (前端 + 后端)

### 3.1 动态配置接口
- 新增 `POST /api/config/validate`: 接收服务商、Key、Model，尝试发起一次轻量级请求验证有效性。
- 新增 `POST /api/config/update`: 更新系统的运行时配置（不重启服务）。

### 3.2 额度耗尽处理 (前端)
- **全局拦截器**: 在 `fetch` 请求层增加拦截逻辑。
- **触发条件**: 当后端返回特定错误码（如 402, 401 或自定义 "QuotaExhausted"）时。
- **交互组件**: 
  - 弹出 Bootstrap Modal（模态框）。
  - 表单包含：**模型服务商** (下拉: DashScope/OpenAI)、**API Key** (密码框)、**模型名称** (输入框)。
  - **验证与重试**: 用户点击确定 -> 调用 `validate` -> 成功后调用 `update` -> 自动重试之前失败的请求。

## 4. 实施路线图

1.  **数据库变更**: 更新 `KnowledgeDocument` 表结构（增加摘要字段），创建 `CacheEntry` 表。
2.  **后端重构**: 实现 `CacheService` 和 `ModelDispatcher`。
3.  **前端开发**: 实现全局错误拦截与配置弹窗组件。
4.  **联调与验证**: 模拟额度耗尽场景，测试缓存命中率。
